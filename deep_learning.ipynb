{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.metrics import BinaryAccuracy, AUC\n",
    "# Function to create model, required for KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_shape=(8,), activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "# load dataset\n",
    "dataset = np.loadtxt(\"data.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Instatiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(model=create_model, verbose=0, metrics=['acc', f1_m, precision_m, recall_m], metrics__threshold=0.65)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results without using Cross Validated Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(X, Y, validation_split=0.3, epochs=10, verbose=0, batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5416666666666666\n"
     ]
    }
   ],
   "source": [
    "predict = model.score(X,Y)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.704427 using {'batch_size': 40, 'epochs': 100}\n",
      "0.537760 (0.021710) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.656250 (0.005524) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.696615 (0.003683) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.604167 (0.019488) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.651042 (0.029463) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.678385 (0.008027) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.606771 (0.016367) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.661458 (0.045143) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.704427 (0.022402) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.584635 (0.046256) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.638021 (0.020505) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.643229 (0.011201) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.533854 (0.126148) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.645833 (0.025780) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.622396 (0.074822) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.565104 (0.046146) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.626302 (0.020505) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.643229 (0.008027) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The final score is: 0.7278645833333334'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "f\"The final score is: {grid_result.score(X,Y)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {'batch_size' :batch_size, 'epochs':epochs}\n",
    "randm_src = RandomizedSearchCV(estimator=model, param_distributions = parameters, cv = 2, n_iter = 10, n_jobs=-1)\n",
    "rand_result = randm_src.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.703125 using {'epochs': 100, 'batch_size': 20}\n",
      "0.703125 (0.015625) with: {'epochs': 100, 'batch_size': 20}\n",
      "0.541667 (0.104167) with: {'epochs': 10, 'batch_size': 100}\n",
      "0.589844 (0.069010) with: {'epochs': 50, 'batch_size': 100}\n",
      "0.592448 (0.048177) with: {'epochs': 50, 'batch_size': 80}\n",
      "0.619792 (0.026042) with: {'epochs': 100, 'batch_size': 100}\n",
      "0.570312 (0.080729) with: {'epochs': 10, 'batch_size': 80}\n",
      "0.677083 (0.002604) with: {'epochs': 50, 'batch_size': 60}\n",
      "0.644531 (0.003906) with: {'epochs': 50, 'batch_size': 40}\n",
      "0.674479 (0.018229) with: {'epochs': 50, 'batch_size': 20}\n",
      "0.587240 (0.066406) with: {'epochs': 10, 'batch_size': 60}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The final score is: 0.7513020833333334'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "means = rand_result.cv_results_['mean_test_score']\n",
    "stds = rand_result.cv_results_['std_test_score']\n",
    "params = rand_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "f\"The final score is: {rand_result.score(X,Y)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using Nested CV --> KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# define search space\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "space = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "# execute search\n",
    "result = search.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.690104 using {'batch_size': 10, 'epochs': 100}\n",
      "0.640625 (0.009568) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.653646 (0.023073) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.690104 (0.004872) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.506510 (0.103070) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.660156 (0.052698) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.688802 (0.004872) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.578125 (0.053274) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.651042 (0.012075) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.664062 (0.031412) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.532552 (0.027498) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.595052 (0.051560) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.644531 (0.019137) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.527344 (0.049101) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.669271 (0.011201) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.664062 (0.019401) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.511719 (0.075003) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.600260 (0.052440) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.654948 (0.038450) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The final score is: 0.7408854166666666'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\n",
    "means = result.cv_results_['mean_test_score']\n",
    "stds = result.cv_results_['std_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "f\"The final score is: {result.score(X,Y)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning Using Nested CV --> Stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "scv = StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "space = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# define search\n",
    "ssearch = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=scv)\n",
    "# execute search\n",
    "hresult = ssearch.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.690104 using {'batch_size': 40, 'epochs': 100}\n",
      "0.569010 (0.037760) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.644531 (0.024740) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.657552 (0.014323) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.506510 (0.001302) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.675781 (0.037760) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.618490 (0.061198) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.553385 (0.032552) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.617188 (0.052083) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.690104 (0.002604) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.549479 (0.041667) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.613281 (0.006510) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.661458 (0.013021) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.634115 (0.006510) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.571615 (0.022135) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.639323 (0.022135) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.617188 (0.033854) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.611979 (0.007812) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.553385 (0.053385) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The final score is: 0.71875'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (hresult.best_score_, hresult.best_params_))\n",
    "means = hresult.cv_results_['mean_test_score']\n",
    "stds = hresult.cv_results_['std_test_score']\n",
    "params = hresult.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "f\"The final score is: {hresult.score(X,Y)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning Using Nested CV --> Repeated KFolds / Repeated Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "rcv = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "space = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# define search\n",
    "rsearch = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=rcv)\n",
    "# execute search\n",
    "rresult = rsearch.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.694010 using {'batch_size': 10, 'epochs': 100}\n",
      "0.600260 (0.048107) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.642578 (0.025936) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.694010 (0.033171) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.593099 (0.033521) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.662760 (0.015461) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.662760 (0.021904) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.528646 (0.049066) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.598307 (0.042924) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.674479 (0.008831) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.525391 (0.072271) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.635417 (0.048265) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.666016 (0.012939) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.523438 (0.113289) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.585938 (0.042112) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.613281 (0.041524) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.541016 (0.106904) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.586589 (0.038246) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.611979 (0.027375) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The final score is: 0.6783854166666666'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (rresult.best_score_, rresult.best_params_))\n",
    "means = rresult.cv_results_['mean_test_score']\n",
    "stds = rresult.cv_results_['std_test_score']\n",
    "params = rresult.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "f\"The final score is: {rresult.score(X,Y)}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
