{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use scikit-learn to grid search the batch size and epochs\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.metrics import BinaryAccuracy, AUC\n",
    "# Function to create model, required for KerasClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DL Model Creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(12, input_shape=(8,), activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid'))\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fix random seed for reproducibility\n",
    "seed = 7\n",
    "tf.random.set_seed(seed)\n",
    "# load dataset\n",
    "dataset = np.loadtxt(\"data.csv\", delimiter=\",\")\n",
    "# split into input (X) and output (Y) variables\n",
    "X = dataset[:, 0:8]\n",
    "Y = dataset[:, 8]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Instatiation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def recall_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_m(y_true, y_pred):\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1_m(y_true, y_pred):\n",
    "    precision = precision_m(y_true, y_pred)\n",
    "    recall = recall_m(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create model\n",
    "model = KerasClassifier(model=create_model, verbose=0, metrics=['acc', f1_m, precision_m, recall_m], metrics__threshold=0.65)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Results without using Cross Validated Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = model.fit(X, Y, validation_split=0.3, epochs=10, verbose=0, batch_size=40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5598958333333334\n"
     ]
    }
   ],
   "source": [
    "predict = model.score(X,Y)\n",
    "print(predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hyperparameter tuning using GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the grid search parameters\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "param_grid = dict(batch_size=batch_size, epochs=epochs)\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.691406 using {'batch_size': 10, 'epochs': 50}\n",
      "0.600260 (0.032578) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.691406 (0.020915) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.669271 (0.009744) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.546875 (0.066826) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.677083 (0.014731) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.662760 (0.024774) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.554688 (0.072940) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.677083 (0.040386) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.665365 (0.017566) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.558594 (0.052505) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.636719 (0.030758) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.625000 (0.071032) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.619792 (0.057439) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.596354 (0.027126) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.640625 (0.025315) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.600260 (0.066317) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.640625 (0.050126) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.643229 (0.017566) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The final score is: 0.7421875'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "f\"The final score is: {grid_result.score(X,Y)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using RandomSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "parameters = {'batch_size' :batch_size, 'epochs':epochs}\n",
    "randm_src = RandomizedSearchCV(estimator=model, param_distributions = parameters, cv = 2, n_iter = 10, n_jobs=-1)\n",
    "rand_result = randm_src.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.687500 using {'epochs': 100, 'batch_size': 20}\n",
      "0.549479 (0.067708) with: {'epochs': 10, 'batch_size': 10}\n",
      "0.640625 (0.026042) with: {'epochs': 10, 'batch_size': 20}\n",
      "0.687500 (0.010417) with: {'epochs': 100, 'batch_size': 20}\n",
      "0.570312 (0.031250) with: {'epochs': 10, 'batch_size': 40}\n",
      "0.484375 (0.028646) with: {'epochs': 10, 'batch_size': 100}\n",
      "0.682292 (0.007812) with: {'epochs': 50, 'batch_size': 10}\n",
      "0.634115 (0.003906) with: {'epochs': 50, 'batch_size': 60}\n",
      "0.628906 (0.006510) with: {'epochs': 50, 'batch_size': 40}\n",
      "0.574219 (0.058594) with: {'epochs': 50, 'batch_size': 100}\n",
      "0.578125 (0.036458) with: {'epochs': 50, 'batch_size': 20}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The final score is: 0.6966145833333334'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (rand_result.best_score_, rand_result.best_params_))\n",
    "means = rand_result.cv_results_['mean_test_score']\n",
    "stds = rand_result.cv_results_['std_test_score']\n",
    "params = rand_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "f\"The final score is: {rand_result.score(X,Y)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter tuning using Nested CV --> KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "cv = KFold(n_splits=3, shuffle=True, random_state=1)\n",
    "# define search space\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "space = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# define search\n",
    "search = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=cv)\n",
    "# execute search\n",
    "result = search.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.700521 using {'batch_size': 10, 'epochs': 100}\n",
      "0.578125 (0.059584) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.662760 (0.004872) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.700521 (0.029635) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.559896 (0.028940) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.661458 (0.008027) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.691406 (0.013902) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.562500 (0.031412) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.651042 (0.012890) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.669271 (0.012890) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.628906 (0.058027) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.585938 (0.088100) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.678385 (0.009207) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.602865 (0.090455) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.638021 (0.031466) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.647135 (0.047771) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.561198 (0.152638) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.609375 (0.044309) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.623698 (0.015733) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The final score is: 0.75'"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (result.best_score_, result.best_params_))\n",
    "means = result.cv_results_['mean_test_score']\n",
    "stds = result.cv_results_['std_test_score']\n",
    "params = result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "f\"The final score is: {result.score(X,Y)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning Using Nested CV --> Stratified KFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import StratifiedKFold\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "scv = StratifiedKFold(n_splits=2, random_state=None, shuffle=False)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "space = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# define search\n",
    "ssearch = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=scv)\n",
    "# execute search\n",
    "hresult = ssearch.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.683594 using {'batch_size': 10, 'epochs': 100}\n",
      "0.626302 (0.076823) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.671875 (0.005208) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.683594 (0.037760) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.598958 (0.013021) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.631510 (0.014323) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.679688 (0.018229) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.550781 (0.050781) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.643229 (0.013021) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.678385 (0.011719) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.524740 (0.014323) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.632812 (0.007812) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.649740 (0.003906) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.578125 (0.085938) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.611979 (0.007812) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.580729 (0.041667) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.623698 (0.029948) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.591146 (0.000000) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.605469 (0.019531) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The final score is: 0.7317708333333334'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (hresult.best_score_, hresult.best_params_))\n",
    "means = hresult.cv_results_['mean_test_score']\n",
    "stds = hresult.cv_results_['std_test_score']\n",
    "params = hresult.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "f\"The final score is: {hresult.score(X,Y)}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter Tuning Using Nested CV --> Repeated KFolds / Repeated Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RepeatedKFold\n",
    "\n",
    "# configure the cross-validation procedure\n",
    "rcv = RepeatedKFold(n_splits=2, n_repeats=2, random_state=2652124)\n",
    "batch_size = [10, 20, 40, 60, 80, 100]\n",
    "epochs = [10, 50, 100]\n",
    "space = dict(batch_size=batch_size, epochs=epochs)\n",
    "\n",
    "# define search\n",
    "rsearch = GridSearchCV(model, space, scoring='accuracy', n_jobs=-1, cv=rcv)\n",
    "# execute search\n",
    "rresult = rsearch.fit(X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best: 0.699219 using {'batch_size': 10, 'epochs': 100}\n",
      "0.621094 (0.035920) with: {'batch_size': 10, 'epochs': 10}\n",
      "0.660807 (0.025805) with: {'batch_size': 10, 'epochs': 50}\n",
      "0.699219 (0.020874) with: {'batch_size': 10, 'epochs': 100}\n",
      "0.511068 (0.077282) with: {'batch_size': 20, 'epochs': 10}\n",
      "0.646484 (0.034419) with: {'batch_size': 20, 'epochs': 50}\n",
      "0.647135 (0.023474) with: {'batch_size': 20, 'epochs': 100}\n",
      "0.583333 (0.016053) with: {'batch_size': 40, 'epochs': 10}\n",
      "0.613281 (0.045124) with: {'batch_size': 40, 'epochs': 50}\n",
      "0.648438 (0.027683) with: {'batch_size': 40, 'epochs': 100}\n",
      "0.585286 (0.022202) with: {'batch_size': 60, 'epochs': 10}\n",
      "0.622396 (0.033197) with: {'batch_size': 60, 'epochs': 50}\n",
      "0.647786 (0.010478) with: {'batch_size': 60, 'epochs': 100}\n",
      "0.483073 (0.064279) with: {'batch_size': 80, 'epochs': 10}\n",
      "0.583984 (0.053095) with: {'batch_size': 80, 'epochs': 50}\n",
      "0.630208 (0.041175) with: {'batch_size': 80, 'epochs': 100}\n",
      "0.477865 (0.129182) with: {'batch_size': 100, 'epochs': 10}\n",
      "0.622396 (0.015073) with: {'batch_size': 100, 'epochs': 50}\n",
      "0.632161 (0.026196) with: {'batch_size': 100, 'epochs': 100}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'The final score is: 0.74609375'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# summarize results\n",
    "print(\"Best: %f using %s\" % (rresult.best_score_, rresult.best_params_))\n",
    "means = rresult.cv_results_['mean_test_score']\n",
    "stds = rresult.cv_results_['std_test_score']\n",
    "params = rresult.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "\n",
    "f\"The final score is: {rresult.score(X,Y)}\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "afb734500600fd355917ca529030176ea0ca205570884b88f2f6f7d791fd3fbe"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
