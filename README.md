ðŸ”¥ Comparing performance of various cross validation techniques for hyperparameter tuning on deep learning architectures ðŸ”¥
---------------------------------------------------------------------------------------------------------------------------

Welcome to the repository for the project on comparing the performance of various cross validation techniques for hyperparameter tuning on deep learning architectures.

### Description

In this project, we aim to compare the performance of different cross validation techniques on various deep learning architectures. Hyperparameter tuning is an important step in training deep learning models, as it can significantly affect the performance of the model. Cross validation is a common technique used for hyperparameter tuning, as it helps to prevent overfitting and ensures that the model generalizes well to unseen data.

However, there are various cross validation techniques available, and it is not clear which technique is the most effective for deep learning models. In this project, we will compare the performance of different cross validation techniques on deep learning architecture.

### Technologies Used

*   Jupyter Notebook
*   Pytorch
*   Scikit-learn
*   Keras
*   Tensorflow

### Contributions

If you would like to contribute to this project, please submit a pull request with a detailed description of your changes. All contributions are welcome and greatly appreciated!

### License

This project is licensed under the BSD 3-Clause License. Please see the [LICENSE](LICENSE) file for more information.
